---
title: "Indel data & viability preprocessing"
author: "Max Trauernicht & Ruben Schep"
date: "`r format(Sys.time(), '%Y-%m-%d')`"
output:
  html_document:
    theme: journal #cerulean
    highlight: monochrome
    toc: true
    toc_float: true
    code_folding: show
  editor_options:
    chunk_output_type: console
---
knitr document van Steensel lab

# Preprocessing of the indel data
# Introduction

In this script I want to prepocess the raw data from the epigenetic screening into one dataframe containing all information: +1/-7 ratio, efficiency, etc. This should all be integrated with the drug and the drug target group corresponding to the well. 
This will be used for plotting indel patterns, calculating ratios later on and such.

* Efficiency (All mutations / Total or (Total - WT sequences) / Total)  
* +1 / -7  


## Description of Data

For this analysis we need the mapping and the indel data of the TRIP integrations. These 
files are obtained with the crispr_trip.snake script that C. Leemans edited. This data 
contains the genomic locations of the TRIP integrations (hg38) and the indel frequencies 
at each integration.

The mutations were called by counting the distance between two constant regions. These
were separated by barcode. The barcodes were also filtered on the starcode, to pick out
the most abundant, and considered real, ones.

Mutations files : *genuine_mapped.table

| barcode  | type | score | 
| ------- | --------- | ----- | 
| TTCTATTCGCACACAA | ins | 1 |
| TTTCCCACATCAGGAG | wt | 0 |
| CCATAGTAGTGATTAC | del | -4 |

# Setup
## Path, Libraries, Parameters and Useful Functions
```{r setup, message=FALSE, warnings=FALSE}
knitr::opts_chunk$set(echo = TRUE)
StartTime <-Sys.time()

# 6-digit Date tag:
Date <- substr(gsub("-","",Sys.time()),1,8) 

## Select outdir
out.dir = paste0("/DATA/projects/DSBrepair/data/R/rs", Date, "_episcreen/")
dir.create(out.dir, showWarnings = FALSE)


# libraries:
library(tidyverse)
library(data.table)
library(ggplot2)
library(parallel)
library(ggpubr)
library(magrittr)
library(cowplot)
library(report)
library(corrr)
library(PerformanceAnalytics)
library(ggbeeswarm)
```

## Custom functions

Functions used include all functions that have been used previously by Ruben (some of them might not be needed anymore, but are kept anyway). Functions 'CallTrueBarcodes' has been added by Max.

```{r functions}
SetFileName <- function(filename, initials) {
  # Set filename with extension and initials to make filename with date integrated.
  filename <- substitute(filename)
  initials <- substitute(initials)
  filename <- paste0(out.dir, initials, substr(gsub("-","",Sys.time()),1,8), filename)
  filename
}

CallTrueBarcodes <- function(df) {
  df %<>% filter(barcode %in% barcodes.clone5)
  df
}
```


## Parameters
```{r}
# initials (for file export)
initials = "rs"

# Viability (% of DMSO)
viab_limit = 0.75

# Read count limit of +1 & -7 combined
read_count_limit = 40
```


# Data import

Data import from mapping, files were generated on 21.01.2019.
```{r import}
# Import files in list and make individual tables
# First list the files from the screen (E177 & 1504). The other will be processed in another script.
file.list <- list.files("/DATA/projects/DSBrepair/data/rs20210628_EpiScreen/indelPCR_counts/",
                        pattern="[E177|E1504]_.*[.]count", full.names=T)

# import the data
df.list <- mclapply(file.list, 
                    read.table, 
                    mc.cores = 20, 
                    header = TRUE, 
                    stringsAsFactors = FALSE, 
                    col.names = c("barcode", "type", 
                                  "mutation", "count"))
# rename the lists
names(df.list) <- gsub(".*?/(.*?)[.]cou.*", "\\1", file.list)
# names(df.list) <- gsub("split", "-", names(df.list))


# names(df.list) <- file.list
# these are the samples
head(names(df.list))
# count the sample number
n.samples <- length(df.list)

# Load the indel statistics with the metadata generated in the parsing script.
indel.statistics.dt = as.data.table(readRDS("/DATA/projects/DSBrepair/git/EpiScreen/files_scripts/rs20211221_Episcreen_Reads_Viab_Metadata.RDS"))

setnames(indel.statistics.dt, 
         c("ID", "viability", "viab_norm", 
           "r_written_pct", "reads"), 
         c("exp", "viability_split", "viab_norm_split", 
           "r_written_pct_split", "reads_split"))

# Import RSTP2 clone 5 barcode list (in total 18 barcodes) - "ACCCCTAAAGGCGCTG" (19) + "CTCTTAATCGCTGCC" (20)
# 19 is very lowly abundant in the sequencing replicate 1 (E177) and therefore omitted
barcodes.clone5 <- c("AGGGCGTAAAATATTT", "TATGGCTGTCGGGTAG", "TGTCCCTTAGTACTTT", 
                   "AGAAAATAATATGACG","CGGCCTGAAGGTCAGG","TTGAACGCGGGCTCGG",
                   "GCTAACATCACGAATC", "GCGCACCCTTTAATTG","ACTGTCGAGTTGTCCG",
                   "CCGGGGACGTATGCAC","TCTTTTGAGGAGCTGA","ATATCGTTGCTGGAGA",
                   "CATCCACCACACTTCA","ATACTATATTTAACGG",
                   "CATTTCTGATCAATAA","GAGCGCGTCACCGGGT",
                   "GTACCTCTCGATAGTG","TGGCCAATATTTGTCT"
                   #,
                   #"ACCCCTAAAGGCGCTG"
                   )
```

## Reading the indel data tables

```{r indel data table list}
# Call true barcodes for clone 5 experiments
df.list = mclapply(df.list, CallTrueBarcodes, mc.cores = 10)

# add name of the processed file to each mutation table and change mutations to char
mut.list = mclapply(names(df.list), function(exp){
  dt = data.table(df.list[[exp]])
  dt[, mutation := as.character(mutation)]
  dt_exp = data.table(exp = exp,
                      dt)
  return(dt_exp)
}, mc.cores = 10)
```


# Processing

## Transform into data table and filtering
Check how many reads are in general not clear or called as point mutations. 

```{r indel dataframe}
# Make a single data.table from the mutations list.
mutations.prefilter.dt = do.call(rbind, c(mut.list, fill = T))
dim(mutations.prefilter.dt) 

# Remove NA counts
mutations.prefilter.dt = mutations.prefilter.dt[!is.na(count)]
dim(mutations.prefilter.dt)

## Not clear reads:
notclear = mutations.prefilter.dt %>% filter(type == "not_clear") %>% pull(count) %>% sum()
all = mutations.prefilter.dt %>%  pull(count) %>% sum()
notclear / all * 100

# remove the inf from the datatable
mutations.prefilter.dt = mutations.prefilter.dt[type != "not_clear"]
dim(mutations.prefilter.dt)
# Point mutations: 
pointmut = mutations.prefilter.dt %>% filter(type == "wt_point_mut") %>% pull(count) %>% sum()
pointmut / all * 100

# remove the point mutations from the datatable
mutations.prefilter.dt = mutations.prefilter.dt[type != "wt_point_mut"]
dim(mutations.prefilter.dt)

## For the time being, let's also remove the +1 and -1 WT. 
# until I understand what Christ means with it
mutations.prefilter.dt = mutations.prefilter.dt[!(type == "wt" & mutation != 0)]
dim(mutations.prefilter.dt)
# same for ssODN as we didn't use it here.
mutations.prefilter.dt = mutations.prefilter.dt[type != "ssODN"]
dim(mutations.prefilter.dt)

setnames(mutations.prefilter.dt, "type", "mut_type")

complete.mutations.dt = mutations.prefilter.dt %>% 
  complete(mutation, nesting(exp, barcode), fill = list(count = 0)) %>% 
  mutate(mut_type = ifelse(mutation < 0, "del", ifelse(mutation > 0, "ins", "wt"))) %>%
  data.table()

dim(complete.mutations.dt)
dim(distinct(complete.mutations.dt))
table(duplicated(complete.mutations.dt[1:200, ]))
```

0.27% of all the reads are not clear and 1.8% of all the reads are point mutations in the guide sequence.

## Normalising counts, calculating frequencies and merging metadata.

```{r merging technical replicates and calculating frequencies}
# First measure the ratio before doing the sum of the technical replicates: 
# We will call the data prior to the technical replicate combination "_split"
setnames(complete.mutations.dt,"count", "count_split")

# Normalise the counts of each sample so that there is no bias due to deeper sequencing depth.
complete.mutations.dt[, norm_split := count_split/sum(count_split), by=exp,]

# Calculate the frequency per technical replicate per barcode & experiment 
# using the normalised counts from before, and the total reads for that barcode. 
complete.mutations.dt[, c("freq_split", "sum_bc_reads_split") := 
               list(norm_split/sum(norm_split, na.rm = TRUE), sum(count_split)), 
             by = c("barcode","exp")]


# Same as above but only conting the indels, ignoring the WT sequence.
complete.mutations.dt[!mutation%in%c(0,NA), 
             ratio_indels_split := norm_split/sum(norm_split, na.rm = TRUE), 
             by=c("barcode","exp")]

complete.mutations.dt[mutation%in%c(1, -7, 0), 
             mut.counts := sum(count_split, na.rm = TRUE), 
             by=c("barcode","exp")]

# Filter the data for at least 100 reads per barcode
length(unique(complete.mutations.dt$exp))
length(unique(complete.mutations.dt[sum_bc_reads_split < 100]$exp))

# Filter on minimal 30 reads per +1/-7 reads
length(unique(complete.mutations.dt[mut.counts < 40]$exp))

E177_pre = sum(grepl("E177", unique(complete.mutations.dt$exp)))
E1504_pre = sum(grepl("E1504", unique(complete.mutations.dt$exp)))

# # Filter with 100 min reads per barcode
# filtered.sumreads.dt =
#   unique(complete.mutations.dt[sum_bc_reads_split >= 100, c("exp", "barcode",  "sum_bc_reads_split")])
# 
# E177_post = sum(grepl("E177", unique(filtered.sumreads.dt$exp)))
# E1504_post = sum(grepl("E1504", unique(filtered.sumreads.dt$exp)))
# 
# # Samples are removed from quite some wells.
# length(unique(filtered.sumreads.dt$exp))
# # Number of wells with removed IPRs
# E177_pre - E177_post
# # Number of wells with removed IPRs
# E1504_pre - E1504_post

# Filter with 30 min reads per barcode like Xabi did.
filtered.indelreads.dt = 
  unique(complete.mutations.dt[!is.na(complete.mutations.dt$mut.counts) & 
                                 mut.counts >= read_count_limit, 
                               c("exp", "barcode", "mut.counts")])

# List all exp names in previous table
exps = unique(filtered.indelreads.dt$exp)

# List all the exps that still contain all the barcodes after count filtering 
filtered.indelreads.exp = exps[table(filtered.indelreads.dt$exp) == length(barcodes.clone5)]

E177_post = sum(grepl("E177", unique(filtered.indelreads.dt$exp)))
E1504_post = sum(grepl("E1504", unique(filtered.indelreads.dt$exp)))

# Samples are removed from quite some wells. 
length(unique(filtered.indelreads.dt$exp))
# Number of wells with removed IPRs
E177_pre - E177_post
# Number of wells with removed IPRs
E1504_pre - E1504_post

mutations.dt = complete.mutations.dt %>% 
  filter(exp %in% filtered.indelreads.exp)

# check if lowest mut.count is 30
mutations.dt %>% 
  filter(!is.na(mut.counts)) %>% 
  pull(mut.counts) %>% 
  min()

dim(complete.mutations.dt)
dim(mutations.dt)

# Add an ID column that removes the technical replicates information 
mutations.dt[, ID := gsub("^(E1504|E177)_[0-9][0-9]_(1|10|100)_[123]_([12]_...$)", 
                          "\\1_\\2_\\3", 
                          exp, 
                          perl = TRUE)]
# Merge the indel statistics
mutations.stat.dt = merge(mutations.dt, indel.statistics.dt)

# Filter the low viability reads
# This filters out all drugs at a certain concentration were at least 2/3 technical replicates were below 0.75 in at least one biological replicate 
keep_drugs <- mutations.stat.dt %>%
  distinct(plate, drug, conc_char, well, tech, replicate, viab_norm_split) %>%
  # filter for samples with higher viab than the limit
  filter(viab_norm_split > viab_limit) %>%
  distinct(conc_char, drug, tech, replicate) %>%
  mutate(conc_char_drug = paste(conc_char, drug, sep = " "),
         tech_n = ave(conc_char_drug, conc_char_drug, replicate, FUN = length),
         conc_char_drug_rep = paste(conc_char, drug, replicate, sep = " ")) %>%
  # These conditions need to be present in at least 2 (out of 3) technical replicates per bio replicate
  filter(tech_n > 1) %>% 
  distinct(replicate, conc_char_drug, conc_char_drug_rep) %>%
  mutate(rep_n = ave(conc_char_drug,conc_char_drug, FUN = length)) %>%
  # And in both bio replicates
  filter(rep_n > 1) %>% 
  pull(conc_char_drug_rep) %>%
  unique()

dim(mutations.stat.dt)
# Filter for the viability
mutations.screen.dt <- mutations.stat.dt %>%
  # filter out technical replicates below the viability cutoff
  filter(viab_norm_split > viab_limit) %>%
  # make filter for the conditions for which we do not have at least 2 technical replicates
  mutate(conc_char_drug_rep = paste(conc_char, drug, replicate, sep = " ")) %>%
  # apply filter
  filter(conc_char_drug_rep %in% keep_drugs) %>%
  # remove these colums
  dplyr::select(-conc_char_drug_rep, -mut.counts) %>%
  # Calculate new mean
  mutate(viab_mean = ave(viab_norm_split, drug, conc_char, replicate, FUN = mean))

dim(mutations.screen.dt)

# Quick random check of the data for a specific barcode and drug: 
mutations.screen.dt[barcode == "ACTGTCGAGTTGTCCG" & drug == "Zebularine" & mutation == -7, 
                -c("mut_type", "file", "seq_barcode", "seq_index", "well", 
                   "barcode", "mutation", "index_length", "drug_no", "drug_well")]

mutations.screen.dt[is.na(mutation), ]
```

## We will also remove samples that are not in at least in 2 technical replicates (out of 3) and are present both biological replicates. 

```{r filter for reproducibility}
mutations.screen.dt %>% 
  distinct(concentration, replicate, tech, drug) %>% 
  group_by(concentration, replicate, drug) %>% 
  dplyr::summarise(count = n()) %>% 
  filter(count < 2)

mutations.screen.dt %>% 
  distinct(concentration, replicate, drug) %>% 
  group_by(concentration, drug) %>% 
  dplyr::summarise(count = n()) %>% 
  filter(count < 2)
```

These two tables are empty, that means that all the samples we have here are all in at least 2 same screen replicates and 2 difference screen replicates.


## Pooling large indels for indel spectrum plotting

```{r large indel pooling for indel plots}
# Fix large deletions for every deletion above 25 (we do not sequence deletions larger than 130 bp)
largedels <- as.character(seq(-130, -15))

mutations.large.del.dt = mutations.screen.dt[mutation %in% largedels, ]

# Sum large dels
mutations.large.del.sum.dt = 
  mutations.large.del.dt[, lapply(.SD, sum, na.rm=TRUE), 
                         by=c("exp", "barcode"),
                         .SDcols=c("count_split",  
                                   "norm_split", "freq_split", "sum_bc_reads_split",
                                   "ratio_indels_split")]
# Add indel info
mutations.large.del.sum.dt[, c("mutation", "mut_type") := list("<-14", "del")]

mutations.large.del.sum.dt[is.na(mutation), ]

# Make base data table with columns except the 2 1st ones (exp & barcode)
colslargedels = colnames(mutations.large.del.sum.dt)[3:ncol(mutations.large.del.sum.dt)]

base.dt = mutations.screen.dt %>% 
  select(!all_of(colslargedels)) %>% distinct()

# Merge the base DT with groupe larde dels
mutations.large.del.sum.base.dt = base.dt %>% 
  left_join(mutations.large.del.sum.dt, by = c("exp", "barcode")) %>% 
  distinct()

dim(mutations.large.del.sum.base.dt)

mutations.large.del.sum.base.dt[is.na(mutation), ]


# Fix large insertions for every insertions above 3
largeins <- as.character(seq(3, 20))
mutations.large.ins.dt = mutations.screen.dt[mutation %in% largeins, ]

# Sum large ins
mutations.large.ins.sum.dt = mutations.large.ins.dt[, lapply(.SD, sum, na.rm=TRUE),  by=c("exp", "barcode"),
                                                .SDcols=c("count_split",  
                                                          "norm_split", "freq_split", "sum_bc_reads_split",
                                                          "ratio_indels_split")]
# Add indel info
mutations.large.ins.sum.dt[, c("mutation", "mut_type") := list(">2", "ins")]

# Merge the base DT with groupe larde ins
mutations.large.ins.sum.base.dt = base.dt %>% 
  left_join(mutations.large.ins.sum.dt, by = c("exp", "barcode")) %>% 
  distinct()

mutations.large.ins.sum.base.dt[is.na(mutation), ]

large.indels.dt = rbind(mutations.large.del.sum.base.dt, 
                        mutations.large.ins.sum.base.dt) %>% 
  distinct()

muts <- unique(mutations.screen.dt$mutation)
min_indel <- min(as.numeric(muts))
max_indel <- max(as.numeric(muts))
indels <- c("<-14", as.character(seq(min_indel, max_indel)), ">2")

setcolorder(large.indels.dt,colnames(mutations.screen.dt))

screen.indel.dt = rbind(mutations.screen.dt, large.indels.dt) %>% 
  distinct()
screen.indel.dt[, c("sample", "type", "color") :=  list(
  # Add column with controls vs drug for plotting also
  ifelse(drug == "DMSO", "DMSO (neg control)", ifelse(
  drug == "DNA-PKi", "DNA-PKi (NHEJ control)", ifelse(
    drug == "Mirin", "Mirin (MMEJ control)", ifelse(
      drug == "PAO", "PAO (killing control)", "drug")))),
  # Add column to identify core, grouped (large) indels or large indels (individual)
  ifelse(mutation %in% c(largedels, largeins), "large_indel", 
         ifelse(mutation %in% c("<-14", ">2"), "grouped_indel", "core")),
  # Add column with color for plotting ease
  ifelse(mutation == 0, "wt", 
         ifelse(mutation == 1, "NHEJ", 
                ifelse(mutation == -7, "MMEJ", "other"))))]

# Make factor from mutations, so plotting is made easy
screen.indel.dt[, mutation := factor(screen.indel.dt$mutation, levels=indels)]

dim(screen.indel.dt)
# Finally remove all the count = 0 now that the ratios have been calculated
```

## R cleanup
```{r cleanup}
rm(list = ls()[grep("^mutations", ls())])
rm(list = ls()[grep("list$", ls())])
rm(list = ls()[grep("large.indels.dt", ls())])
rm(list = ls()[grep("mutations.dt", ls())])
```

## Add identifiers and compute indel ratios

```{r calculate_ratios}
# Calculate NHEJ/MMEJ ratios and efficiences
ratios_tib <- screen.indel.dt %>%
  filter(mutation %in% c("1", "-7")) %>%
  dplyr::distinct(exp, barcode, mutation, ratio_indels_split) %>% 
  pivot_wider(names_from = mutation, 
              values_from = ratio_indels_split, 
              values_fill = 0) %>%
  mutate(freqMMEJ = `-7` / 1,
         freqNHEJ = `1` / 1,
         MMEJratio = freqMMEJ / freqNHEJ,
         NHEJratio = freqNHEJ / freqMMEJ,
         MMEJscore = freqMMEJ / (freqMMEJ + freqNHEJ),
         NHEJscore = freqNHEJ / (freqNHEJ+ freqMMEJ)) %>%
  distinct(exp, barcode, freqMMEJ, freqNHEJ, MMEJratio, NHEJratio, MMEJscore, NHEJscore) 


freqs_ratios_tib <- screen.indel.dt %>%
  as_tibble() %>%
  filter(mutation == "0") %>%
  dplyr::distinct(exp, barcode, mutation, freq_split) %>% 
  mutate(freqCut = 1 - freq_split,
         freqCut_global = ave(freqCut, exp, FUN = mean)) %>%
  distinct(exp, barcode, freqCut, freqCut_global) %>% 
  left_join(ratios_tib, by = c("exp", "barcode"))

screen.indel.dt = left_join(screen.indel.dt, freqs_ratios_tib, by = c("exp", "barcode"))

dim(screen.indel.dt)

```

## Calculate mean indel frequencies
```{r split table for indels}
indel.cols = c("replicate",
         "barcode",
         "tech",
         "exp",
         "mutation",
         "mut_type",
         "count_split",
         "norm_split",
         "freq_split",
         "sum_bc_reads_split",
         "ratio_indels_split",
         "ID",
         "concentration",
         "drug_plate",
         "drug",
         "target",
         "viab_norm_split",
         "conc_char",
         "viab_mean",
         "sample",
         "type",
         "color")

screen.indels.dt = screen.indel.dt %>% select(all_of(indel.cols))

indel.cols.only = c(
         "mutation",
         "mut_type",
         "count_split",
         "norm_split",
         "freq_split",
         "freq_mean_rep",
         "freq_mean",
         "freq_sd_rep",
         "freq_sd",
         "sum_bc_reads_split",
         "ratio_indels_split",
         "type",
         "color")

screen.ratio.dt = screen.indel.dt %>% select(-any_of(indel.cols.only)) %>% distinct()
```

```{r averaging indel frequencies}
screen.indels.dt %<>% as.data.table()

screen.indels.dt[, 
                c("freq_mean_rep", "freq_sd_rep") := 
                  list(mean(freq_split, na.rm = TRUE), 
                       sd(freq_split, na.rm = TRUE)), 
                by=c("barcode", "mutation", "replicate", "drug", "conc_char")] 

screen.indels.dt[, 
                c("freq_mean", "freq_sd") := 
                  list(mean(freq_split, na.rm = TRUE), 
                       sd(freq_split, na.rm = TRUE)), 
                by=c("barcode", "mutation", "drug", "conc_char")]  
```

# Calculating the z-scores

## Data plotting

### Checking DMSO data distribution

Before calculating the z-scores we need to check the DMSO data distribution if it's normal or not.
First the general distribution in a bee swarm plot per barcode.

```{r plotting the balance and efficiency per barcode, eval = FALSE, echo = FALSE}
for (i in barcodes.clone5) {
  norm_pooled = screen.ratio.dt %>%
    filter(drug == "DMSO", barcode == i) %>%
    distinct(ID, barcode, freqCut, MMEJscore, replicate, tech)
  plt1 = ggplot(norm_pooled, aes(replicate, freqCut, color = as.character(tech))) + 
    geom_quasirandom() +
    stat_summary(fun=mean, aes(shape="mean", color = "mean"), geom="point") +
    stat_summary(fun=median, aes(shape="median", color = "median"), geom="point") +
    scale_shape_manual(values=c("mean"= 15, "median" = 16)) +
    scale_color_manual(values=c("1"= "gray80", "2"= "gray50", "3"= "gray20", "mean"= "red", "median" = "blue"))+
    ylim(0.3, 1) +
    theme_bw() +
    ggtitle(paste0("freqCut Barcode: ", i))
  plt2 = ggplot(norm_pooled, aes(replicate, MMEJscore, color = as.character(tech))) + 
    geom_quasirandom() +
    stat_summary(fun=mean, aes(shape="mean", color = "mean"), geom="point") +
    stat_summary(fun=median, aes(shape="median", color = "median"), geom="point") +
    scale_shape_manual(values=c("mean"= 15, "median" = 16)) +
    scale_color_manual(values=c("1"= "gray80", "2"= "gray50", "3"= "gray20", "mean"= "red", "median" = "blue"))+
    ylim(0, 0.6) +
    theme_bw() +
    ggtitle(paste0("MMEJscore Barcode: ", i))
  print(plot_grid(plt1, plt2))
}

# same by concentration
for (i in barcodes.clone5) {
  norm_pooled = screen.ratio.dt %>%
    filter(drug == "DMSO", barcode == i) %>%
    distinct(ID, barcode, freqCut, MMEJscore, replicate, concentration)
  plt1 = ggplot(norm_pooled, aes(replicate, freqCut, color = as.character(concentration))) + 
    geom_quasirandom() +
    stat_summary(fun=mean, aes(shape="mean", color = "mean"), geom="point") +
    stat_summary(fun=median, aes(shape="median", color = "median"), geom="point") +
    scale_shape_manual(values=c("mean"= 15, "median" = 16)) +
    scale_color_manual(values=c("100"= "gray80", "1"= "gray50", "10"= "gray20", "mean"= "red", "median" = "blue"))+
    ylim(0.3, 1) +
    theme_bw() +
    ggtitle(paste0("freqCut Barcode: ", i))
  plt2 = ggplot(norm_pooled, aes(replicate, MMEJscore, color = as.character(concentration))) + 
    geom_quasirandom() +
    stat_summary(fun=mean, aes(shape="mean", color = "mean"), geom="point") +
    stat_summary(fun=median, aes(shape="median", color = "median"), geom="point") +
    scale_shape_manual(values=c("mean"= 15, "median" = 16)) +
    scale_color_manual(values=c("100"= "gray80", "1"= "gray50", "10"= "gray20", "mean"= "red", "median" = "blue"))+
    ylim(0, 0.6) +
    theme_bw() +
    ggtitle(paste0("MMEJscore Barcode: ", i))
  print(plot_grid(plt1, plt2))
}
```
We can observe some outliers but in general the data is quite reproducible. Some notes:
- The efficiency for technical replicates, especially in E1504 seems to group together. This is important to note for the normalization of the drug effect on the efficiency. 
- Barcode ACCCCTAAAGGCGCTG has a very large range in E177 for some reason.
- Mean and median are very similar, it's good enough to use the mean in all the cases.


### Checking for data normality

Check if the DMSO data is normally distributed for MMEJscore and freqCut with qqplots. 

```{r check for normal distribution, eval = FALSE, echo = FALSE}
for (i in barcodes.clone5) {
  norm_pooled = screen.ratio.dt %>%
    filter(drug == "DMSO", barcode == i) %>%
    distinct(ID, barcode, freqCut, MMEJscore, replicate)
  plt1 = qplot(sample = freqCut, data = norm_pooled, color=replicate) +
    theme_bw() +
    ggtitle(paste0("pooled freqCut Barcode: ", i))
  plt2 = qplot(sample = MMEJscore, data = norm_pooled, color=replicate) +
    theme_bw() +
    ggtitle(paste0("pooled MMEJscore Barcode: ", i))
  print(plot_grid(plt1, plt2))
}
```

Some samples have clear outlyers, others aren't prefectly normally distributed but in general it's rather good.

## Calculating the z-scores and normalised efficiencies

```{r efficiency normalisation to DMSO values}
# Plate normalization for cutting/repair efficiency - 
# calculate efficiency relative to mean DMSO efficiency per concentration, barcode and replicate
# First a table with DMSO efficiency per barcode, per technical replicate. 

dmso.efficiency <- screen.ratio.dt %>%
  filter(drug == "DMSO") %>%
  distinct('DMSO' = freqCut, 'DMSO_global' = freqCut_global, barcode, replicate,
         tech, well, drug_plate) %>%
  mutate(DMSO = ave(DMSO, barcode, replicate, tech, FUN = mean)) %>% # mean per technical replicate
  mutate(DMSO_global = ave(DMSO_global, replicate, tech, FUN = mean)) %>%
  dplyr::select(-drug_plate, -well) %>%
  distinct()

screen.ratio.dt <- left_join(screen.ratio.dt, dmso.efficiency)

screen.ratio.dt <- screen.ratio.dt %>%
  mutate(freqCut_norm = freqCut / DMSO,
         freqCut_norm_global = freqCut_global / DMSO_global) %>%
  group_by(barcode, ID) %>% # group by ID and barcode for mean efficiency per well and barcode (remove technical replicates)
  mutate(freqCut_norm_mean = mean(freqCut_norm),
         freqCut_norm_global_mean = mean(freqCut_norm_global)) %>%
  ungroup()


dim(screen.indel.dt)
dim(screen.ratio.dt)
```

## Efficiency z-score calculation

```{r prep for efficiency z-scores}
# First calculate means and sd of the DMSO efficiency per replicate and barcode
dmso.eff.score <- screen.ratio.dt %>%
  filter(drug == "DMSO") %>%
  dplyr::select('DMSO' = freqCut, well, barcode, replicate, tech, plate) %>%
  mutate(DMSO = ave(DMSO, barcode, well, replicate, tech, plate, FUN = mean)) %>%
  distinct(barcode, replicate, tech, well, plate, DMSO) %>%
  mutate(mean_DMSO = ave(DMSO, barcode, replicate, tech, FUN = mean), 
         sd_DMSO = ave(DMSO, barcode, replicate, tech, FUN = sd)
         #,
         #mean_DMSO_pooled = ave(DMSO, barcode, replicate, FUN = mean), 
         #sd_DMSO_pooled = ave(DMSO, barcode, replicate, FUN = sd)
         ) %>%
  dplyr::select(-DMSO, -well) %>%
  distinct() 

dmso.eff.score <- screen.ratio.dt %>%
    filter(drug == "DMSO") %>%
  distinct('DMSO_global' = freqCut_global, replicate, tech, well, plate) %>%
  mutate(DMSO_global = ave(DMSO_global, replicate, tech, well, plate, FUN = mean)) %>%
  distinct(replicate, tech, well, plate, DMSO_global) %>%
  mutate(mean_DMSO_global = ave(DMSO_global, replicate, tech, FUN = mean), 
         sd_DMSO_global = ave(DMSO_global, replicate, tech, FUN = sd)
         #,
         #mean_DMSO_global_pooled = ave(DMSO_global, replicate, FUN = mean), 
         #sd_DMSO_global_pooled = ave(DMSO_global, replicate, FUN = sd)
         ) %>%
  dplyr::select(-DMSO_global, -well) %>%
  distinct() %>% right_join(dmso.eff.score)

screen.ratio.dt = left_join(screen.ratio.dt, dmso.eff.score)
```


```{r calculate efficiency z-scores}
# Calculate IPR z-scores
eff.zscore = screen.ratio.dt %>%
  distinct(barcode, replicate, tech, drug, well, freqCut, conc_char, 
           mean_DMSO, sd_DMSO) %>%
  # Then calculate the mean over the technical replicates
  #mutate(eff_score_mean = ave(freqCut, drug, conc_char, barcode, replicate, FUN = mean)) %>%
  # And calculate the z-scores
  mutate(eff_zscore = (freqCut - mean_DMSO)/ sd_DMSO,
         #eff_zscore_pooled = (eff_score_mean - mean_DMSO_pooled)/ sd_DMSO_pooled,
         mean_eff_zscore = ave(eff_zscore, drug, conc_char, barcode, replicate, FUN = mean)
         #,
         #eff_zscore_comb = ave(eff_zscore, drug, conc_char, barcode, 
         #                       FUN = function(x) sum(x)/sqrt(length(x))
         )


# Combine the mean of the z-scores
mean.eff.zscore.comb = eff.zscore %>% distinct(drug, conc_char, barcode, replicate, mean_eff_zscore) %>%
         mutate(mean_eff_zscore_comb = ave(mean_eff_zscore, drug, conc_char, barcode, 
                                FUN = function(x) sum(x)/sqrt(length(x))))

# # Combine the mean z-scores
# eff.zscore.pooled.comb = eff.zscore %>% distinct(drug, conc_char, barcode, replicate, eff_zscore_pooled) %>%
#          mutate(eff_zscore_pooled_comb = ave(eff_zscore_pooled, drug, conc_char, barcode, 
#                                 FUN = function(x) sum(x)/sqrt(length(x)))) %>% 
#   left_join(mean.eff.zscore.comb)

eff.zscore %<>% left_join(mean.eff.zscore.comb)
```

```{r calculate global efficiency z-scores}
# Calculate global z-scores
eff.zscore.global = screen.ratio.dt %>%
  distinct(replicate, tech, drug, well, freqCut_global, conc_char, 
           mean_DMSO_global, sd_DMSO_global) %>%
  # Then calculate the mean over the technical replicates
  #mutate(eff_score_global_mean = ave(freqCut_global, drug, conc_char, replicate, FUN = mean)) %>%
  # And calculate the z-scores
  mutate(eff_zscore_global = (freqCut_global - mean_DMSO_global)/ sd_DMSO_global) %>%
         #eff_zscore_pooled_global = (eff_score_global_mean - 
                                       #mean_DMSO_global_pooled) / sd_DMSO_global_pooled) %>%
  mutate(mean_eff_zscore_global = ave(eff_zscore_global, drug, conc_char, replicate, FUN = mean))

# Combine the global z-scores
eff.zscore.pooled.global.comb = eff.zscore.global %>% 
  distinct(drug, conc_char, replicate, mean_eff_zscore_global) %>%
         # mutate(eff_zscore_pooled_global_comb = ave(eff_zscore_pooled_global, drug, conc_char, 
         #                        FUN = function(x) sum(x)/sqrt(length(x)))) %>%
         mutate(mean_eff_zscore_global_comb = ave(mean_eff_zscore_global, drug, conc_char, 
                                FUN = function(x) sum(x)/sqrt(length(x))))

eff.zscore.global %<>% left_join(eff.zscore.pooled.global.comb)


eff.zscore %<>% left_join(eff.zscore.global) %>% 
  select(-mean_DMSO, 
         -sd_DMSO,
         #-mean_DMSO_pooled, 
         #-sd_DMSO_pooled,
         -mean_DMSO_global, 
         -sd_DMSO_global,
         #-mean_DMSO_global_pooled, 
         #-sd_DMSO_global_pooled
  )

# Merge with main table
screen.ratio.dt <- left_join(screen.ratio.dt, 
                             eff.zscore) %>% 
  select(-mean_DMSO, 
         -sd_DMSO,
         #-mean_DMSO_pooled, 
         #-sd_DMSO_pooled,
         -mean_DMSO_global, 
         -sd_DMSO_global,
         #-mean_DMSO_global_pooled, 
         #-sd_DMSO_global_pooled
         )
```

## Pathway ratio z-score calculation

```{r z-score calculation}
# MMEJscore z-score - calculate drug scores relative to DMSO MMEJ score distribution per concentration, barcode and replicate

# First calculate means and sd of the DMSO MMEJ score per replicate and barcode
dmso.mmej.score <- screen.ratio.dt %>%
  filter(drug == "DMSO") %>%
  ungroup() %>%
  distinct(barcode, replicate, tech, drug, well, plate, MMEJratio) %>%
  dplyr::select('DMSO' = MMEJratio, barcode, replicate, tech) %>%
  mutate(mean_DMSO = ave(DMSO, barcode, replicate, tech, FUN = mean), 
         sd_DMSO = ave(DMSO, barcode, replicate, tech, FUN = sd)) %>%
  dplyr::select(-DMSO) %>%
  distinct()

# Merge with main table
screen.ratio.dt <- left_join(screen.ratio.dt, dmso.mmej.score, by = c("barcode", "replicate", "tech"))

screen.ratio.dt <- screen.ratio.dt %>%
  # Then calculate the mean over the technical replicates
  #mutate(MMEJ_ratio_mean = ave(MMEJratio, drug, concentration, barcode, replicate, FUN = mean)) %>%
  # And calculate the z-scores
  mutate(MMEJ_ratio_norm = MMEJratio / mean_DMSO) %>%
  mutate(MMEJ_zscore = (MMEJratio - mean_DMSO)/ sd_DMSO) %>%
  mutate(MMEJ_zscore_mean = ave(MMEJ_zscore, drug, conc_char, replicate, barcode, FUN = mean)) %>%
  dplyr::select(-mean_DMSO, -sd_DMSO)


# Mean values independent of IPR (mean effect of the drug)
dmso.mmej.score <- screen.ratio.dt %>%
  ungroup() %>%
  distinct(replicate, tech, drug, well, plate, MMEJratio) %>%
  filter(drug == "DMSO") %>%
  mutate(MMEJratio = ave(MMEJratio, tech, drug, well, plate, FUN = mean)) %>%
  dplyr::select('DMSO' = MMEJratio, replicate, tech) %>%
  mutate(mean_DMSO = ave(DMSO, replicate, tech, FUN = mean), 
         sd_DMSO = ave(DMSO, replicate, tech, FUN = sd)) %>%
  dplyr::select(-DMSO) %>%
  distinct()

screen.ratio.dt <- left_join(screen.ratio.dt, dmso.mmej.score, by = c("replicate", "tech"))

screen.ratio.dt <- screen.ratio.dt %>%
  mutate(MMEJ_ratio_global = ave(MMEJratio, drug, concentration, replicate, tech, FUN = mean)) %>%
  mutate(MMEJ_zscore_global = (MMEJ_ratio_global - mean_DMSO)/ sd_DMSO) %>%
  mutate(MMEJ_zscore_global_mean = ave(MMEJ_zscore_global, drug, conc_char, replicate, FUN = mean)) %>%
  dplyr::select(-mean_DMSO, -sd_DMSO)
```


```{r combine z-scores}
# Combine z-scores of the two biological replicates: stouffer's method = sum(z-scores)/sqrt(number_of_z-scores)
zscores_comb <- screen.ratio.dt %>%
  distinct(MMEJ_zscore_mean, drug, conc_char, barcode) %>%
  mutate(MMEJ_zscore_comb = ave(MMEJ_zscore_mean, drug, conc_char, barcode, 
                                FUN = function(x) sum(x)/sqrt(length(x)))) 

zscores_comb_global <- screen.ratio.dt %>%
  distinct(MMEJ_zscore_global_mean, drug, conc_char) %>%
  mutate(MMEJ_zscore_global_comb = ave(MMEJ_zscore_global_mean, drug, conc_char, 
                                  FUN = function(x) sum(x)/sqrt(length(x)))) %>%
  distinct(MMEJ_zscore_global_comb, drug, conc_char)

screen.ratio.dt <- left_join(screen.ratio.dt, zscores_comb)
screen.ratio.dt <- left_join(screen.ratio.dt, zscores_comb_global)

```
# Data export

## Add chromatin data

We'll use the table from Schep et al. 2021 to bind directly all the relevant chromatin data. 

```{r add chromatin data}
clone5_z.score_chrom_tib <- readRDS('/DATA/projects/DSBrepair/data/R/cl20201026_ChIP_zscore_selection.RDS') %>%
  filter(pool == "clone_set") %>% 
  setNames(paste0(names(.), ".zscore")) %>% 
  plyr::rename(., c('ID.zscore' = 'barcode')) %>% 
  select(-pool.zscore, -binsize.zscore)


clone5_chrom_tib <- readRDS("/DATA/projects/DSBrepair/data/R/rs20200519_clone5_newdoms_chromatin.RDS") %>%
  filter(IPR != "IPR1") %>%
  left_join(clone5_z.score_chrom_tib)



chrom_colnames = names(clone5_chrom_tib)

screen.ratios.chrom.dt <- screen.ratio.dt %>% left_join(clone5_chrom_tib)
screen.indels.chrom.dt <- screen.indels.dt %>% left_join(clone5_chrom_tib)

rm(screen.ratio.dt)
rm(screen.indels.dt)
```
## Exporting the data tables

We'll make three tables.
- Table with all (large and will use less - also has all metadata)
 - Table with individual mutation data (for indel plotting)
 - Table with only ratios (smaller for most plotting)

```{r split the tables for different scripts}
ratio.cols = c("replicate",
         "barcode",
         "tech",
         "exp",
         "well",
         "plate",
         "ID",
         "concentration",
         "drug",
         "target",
         "viab_norm_split",
         "conc_char",
         "viab_mean",
         "sample",
         "freqCut",
         "freqMMEJ", 
         "freqNHEJ",
         "MMEJratio",
         "MMEJ_ratio_norm",
         "NHEJratio",
         "MMEJscore",
         "NHEJscore",
         "freqCut_norm",
         "freqCut_norm_global",
         "freqCut_norm_mean",
         "freqCut_norm_global_mean",
         "eff_zscore",
         "mean_eff_zscore",
         "mean_eff_zscore_comb",
         "mean_eff_zscore_global_comb",
         "mean_eff_zscore_global",
         "eff_zscore_global",
         "MMEJ_zscore",
         "MMEJ_zscore_mean",
         "MMEJ_zscore_global",
         "MMEJ_zscore_global_mean",
         "MMEJ_zscore_comb" ,
         "MMEJ_zscore_global_comb")

screen_ratios_tib =  screen.ratios.chrom.dt %>% 
  select(all_of(c(ratio.cols, chrom_colnames)))

#rm(screen.indel.chrom.dt)
```


## Processed data export The files will be saved in the processed data folder.
```{r export}
# The mutations list that can be loaded for the indel spectra plots.
filename <- SetFileName("_episcreen_mutations.RDS", initials = initials)
saveRDS(screen.indels.chrom.dt, file = filename)

# The ratios list of the split technical replicates
filename <- SetFileName("_episcreen_ratios.RDS", initials = initials)
saveRDS(screen_ratios_tib, file = filename)

# # The ratios list of the merged technical replicates
# filename <- SetFileName("_episcreen_all.RDS", initials = initials)
# saveRDS(screen_all_tib, file = filename)
```

# Conclusions 
Looks all fine! Now, we can generate indel plots and look in detail at the ratios.

# Bibliography
```{r citations}
cite_packages()
```

# Session Info
```{r session_info}
sessionInfo()
getwd()
date()
paste("Run time: ",format(Sys.time()-StartTime))
rm(list = ls(all.names = TRUE)) #will clear all objects includes hidden objects.
gc() #free up memrory and report the memory usage.
```

