---
title: "Indel data & viability preprocessing"
author: "Max Trauernicht & Ruben Schep"
date: "`r format(Sys.time(), '%Y-%m-%d')`"
output:
  html_document:
    theme: journal #cerulean
    highlight: monochrome
    toc: true
    toc_float: true
    code_folding: show
  editor_options:
    chunk_output_type: console
---
knitr document van Steensel lab

# Preprocessing of the indel data
# Introduction

In this script I want to prepocess the raw data from the epigenetic screening into one dataframe containing all information: +1/-7 ratio, efficiency, etc. This should all be integrated with the drug and the drug target group corresponding to the well. 
This will be used for plotting indel patterns, calculating ratios later on and such.

* Efficiency (All mutations / Total or (Total - WT sequences) / Total)  
* +1 / -7  


## Description of Data

For this analysis we need the mapping and the indel data of the TRIP integrations. These 
files are obtained with the crispr_trip.snake script that C. Leemans edited. This data 
contains the genomic locations of the TRIP integrations (hg38) and the indel frequencies 
at each integration.

The mutations were called by counting the distance between two constant regions. These
were separated by barcode. The barcodes were also filtered on the starcode, to pick out
the most abundant, and considered real, ones.

Mutations files : *genuine_mapped.table

| barcode  | type | score | 
| ------- | --------- | ----- | 
| TTCTATTCGCACACAA | ins | 1 |
| TTTCCCACATCAGGAG | wt | 0 |
| CCATAGTAGTGATTAC | del | -4 |

# Setup
## Path, Libraries, Parameters and Useful Functions
```{r setup, message=FALSE, warnings=FALSE}
knitr::opts_chunk$set(echo = TRUE)
StartTime <-Sys.time()

# 6-digit Date tag:
Date <- substr(gsub("-","",Sys.time()),1,8) 

## Select outdir
out.dir = paste0("/DATA/projects/DSBrepair/data/R/rs", Date, "_episcreen/")
dir.create(out.dir, showWarnings = FALSE)


# libraries:
library(tidyverse)
library(data.table)
library(ggplot2)
library(parallel)
library(ggpubr)
library(magrittr)
library(cowplot)
library(report)
library(corrr)
library(PerformanceAnalytics)
```

## Custom functions

Functions used include all functions that have been used previously by Ruben (some of them might not be needed anymore, but are kept anyway). Functions 'CallTrueBarcodes' has been added by Max.

```{r functions}
SetFileName <- function(filename, initials) {
  # Set filename with extension and initials to make filename with date integrated.
  filename <- substitute(filename)
  initials <- substitute(initials)
  filename <- paste0(out.dir, initials, substr(gsub("-","",Sys.time()),1,8), filename)
  filename
}

CallTrueBarcodes <- function(df) {
  df %<>% filter(barcode %in% barcodes.clone5)
  df
}
```

# Data import

Data import from mapping, files were generated on 21.01.2019.
```{r import}
# Import files in list and make individual tables
# First list the files from the screen (E177 & 1504). The other will be processed in another script.
file.list <- list.files("/DATA/projects/DSBrepair/data/rs20210628_EpiScreen/indelPCR_counts/",
                        pattern="[E177|E1504]_.*[.]count", full.names=T)

# import the data
df.list <- mclapply(file.list, 
                    read.table, 
                    mc.cores = 20, 
                    header = TRUE, 
                    stringsAsFactors = FALSE, 
                    col.names = c("barcode", "type", 
                                  "mutation", "count"))
# rename the lists
names(df.list) <- gsub(".*?/(.*?)[.]cou.*", "\\1", file.list)
# names(df.list) <- gsub("split", "-", names(df.list))


# names(df.list) <- file.list
# these are the samples
head(names(df.list))
# count the sample number
n.samples <- length(df.list)

# Load the indel statistics with the metadata generated in the parsing script.
indel.statistics.dt = as.data.table(readRDS("/DATA/projects/DSBrepair/git/EpiScreen/files_scripts/rs20211221_Episcreen_Reads_Viab_Metadata.RDS"))

setnames(indel.statistics.dt, 
         c("ID", "viability", "viab_norm", 
           "r_written_pct", "reads"), 
         c("exp", "viability_split", "viab_norm_split", 
           "r_written_pct_split", "reads_split"))

# Import RSTP2 clone 5 barcode list (in total 18 barcodes) - "ACCCCTAAAGGCGCTG" (19) + "CTCTTAATCGCTGCC" (20)
# 19 is very lowly abundant in the sequencing replicate 1 (E177) and therefore omitted - #### KEPT FOR NOW #####
barcodes.clone5 <- c("AGGGCGTAAAATATTT", "TATGGCTGTCGGGTAG", "TGTCCCTTAGTACTTT", 
                   "AGAAAATAATATGACG","CGGCCTGAAGGTCAGG","TTGAACGCGGGCTCGG",
                   "GCTAACATCACGAATC", "GCGCACCCTTTAATTG","ACTGTCGAGTTGTCCG",
                   "CCGGGGACGTATGCAC","TCTTTTGAGGAGCTGA","ATATCGTTGCTGGAGA",
                   "CATCCACCACACTTCA","ATACTATATTTAACGG",
                   "CATTTCTGATCAATAA","GAGCGCGTCACCGGGT",
                   "GTACCTCTCGATAGTG","TGGCCAATATTTGTCT",
                   "ACCCCTAAAGGCGCTG")
```

## Reading the indel data tables

```{r indel data table list}
# Call true barcodes for clone 5 experiments
df.list = mclapply(df.list, CallTrueBarcodes, mc.cores = 10)

# add name of the processed file to each mutation table and change mutations to char
mut.list = mclapply(names(df.list), function(exp){
  dt = data.table(df.list[[exp]])
  dt[, mutation := as.character(mutation)]
  dt_exp = data.table(exp = exp,
                      dt)
  return(dt_exp)
}, mc.cores = 10)
```


# Processing

## Transform into data table and filtering
Check how many reads are in general not clear or called as point mutations. 

```{r indel dataframe}
# Make a single data.table from the mutations list.
mutations.prefilter.dt = do.call(rbind, c(mut.list, fill = T))
dim(mutations.prefilter.dt) 

# Remove NA counts
mutations.prefilter.dt = mutations.prefilter.dt[!is.na(count)]
dim(mutations.prefilter.dt)

## Not clear reads:
notclear = mutations.prefilter.dt %>% filter(type == "not_clear") %>% pull(count) %>% sum()
all = mutations.prefilter.dt %>%  pull(count) %>% sum()
notclear / all * 100

# remove the inf from the datatable
mutations.prefilter.dt = mutations.prefilter.dt[type != "not_clear"]
dim(mutations.prefilter.dt)
# Point mutations: 
pointmut = mutations.prefilter.dt %>% filter(type == "wt_point_mut") %>% pull(count) %>% sum()
pointmut / all * 100

# remove the point mutations from the datatable
mutations.prefilter.dt = mutations.prefilter.dt[type != "wt_point_mut"]
dim(mutations.prefilter.dt)

## For the time being, let's also remove the +1 and -1 WT. 
# until I understand what Christ means with it
mutations.prefilter.dt = mutations.prefilter.dt[!(type == "wt" & mutation != 0)]
dim(mutations.prefilter.dt)
# same for ssODN as we didn't use it here.
mutations.prefilter.dt = mutations.prefilter.dt[type != "ssODN"]
dim(mutations.prefilter.dt)

setnames(mutations.prefilter.dt, "type", "mut_type")

complete.mutations.dt = mutations.prefilter.dt %>% 
  complete(mutation, nesting(exp, barcode), fill = list(count = 0)) %>% 
  mutate(mut_type = ifelse(mutation < 0, "del", ifelse(mutation > 0, "ins", "wt"))) %>%
  data.table()
```

0.27% of all the reads are not clear and 1.8% of all the reads are point mutations in the guide sequence.

## Normalising counts, calculating frequencies and merging metadata.

```{r merging technical replicates and calculating frequencies}
# First measure the ratio before doing the sum of the technical replicates: 
# We will call the data prior to the technical replicate combination "_split"
setnames(complete.mutations.dt,"count", "count_split")

# Normalise the counts of each sample so that there is no bias due to deeper sequencing depth.
complete.mutations.dt[, norm_split := count_split/sum(count_split), by=exp,]

# Calculate the frequency per technical replicate per barcode & experiment 
# using the normalised counts from before, and the total reads for that barcode. 
complete.mutations.dt[, c("freq_split", "sum_bc_reads_split") := 
               list(norm_split/sum(norm_split, na.rm = TRUE), sum(count_split)), 
             by = c("barcode","exp")]


# Same as above but only conting the indels, ignoring the WT sequence.
complete.mutations.dt[!mutation%in%c(0,NA), 
             ratio_indels_split := norm_split/sum(norm_split, na.rm = TRUE), 
             by=c("barcode","exp")]

complete.mutations.dt[mutation%in%c(1, -7), 
             mut.counts := sum(count_split, na.rm = TRUE), 
             by=c("barcode","exp")]

# Filter the data for at least 100 reads per barcode
length(unique(complete.mutations.dt$exp))
length(unique(complete.mutations.dt[sum_bc_reads_split < 100]$exp))

# Filter on minimal 30 reads per +1/-7 reads
length(unique(complete.mutations.dt[mut.counts < 30]$exp))

E177_pre = sum(grepl("E177", unique(complete.mutations.dt$exp)))
E1504_pre = sum(grepl("E1504", unique(complete.mutations.dt$exp)))

# # Filter with 100 min reads per barcode
# filtered.sumreads.dt =
#   unique(complete.mutations.dt[sum_bc_reads_split >= 100, c("exp", "barcode",  "sum_bc_reads_split")])
# 
# E177_post = sum(grepl("E177", unique(filtered.sumreads.dt$exp)))
# E1504_post = sum(grepl("E1504", unique(filtered.sumreads.dt$exp)))
# 
# # Samples are removed from quite some wells.
# length(unique(filtered.sumreads.dt$exp))
# # Number of wells with removed IPRs
# E177_pre - E177_post
# # Number of wells with removed IPRs
# E1504_pre - E1504_post

# Filter with 30 min reads per barcode like Xabi did.
filtered.indelreads.dt = 
  unique(complete.mutations.dt[!is.na(complete.mutations.dt$mut.counts) & 
                                 mut.counts >= 30, 
                               c("exp", "barcode", "mut.counts")])
E177_post = sum(grepl("E177", unique(filtered.indelreads.dt$exp)))
E1504_post = sum(grepl("E1504", unique(filtered.indelreads.dt$exp)))

# Samples are removed from quite some wells. 
length(unique(filtered.indelreads.dt$exp))
# Number of wells with removed IPRs
E177_pre - E177_post
# Number of wells with removed IPRs
E1504_pre - E1504_post

mutations.dt = complete.mutations.dt %>% 
  semi_join(select(filtered.indelreads.dt, c("exp", "barcode")), 
            by = c("exp", "barcode")) # This remove the samples that have less than 30 reads.

# check if lowest mut.count is 30
mutations.dt %>% 
  filter(!is.na(mut.counts)) %>% 
  pull(mut.counts) %>% 
  min()

dim(complete.mutations.dt)
dim(mutations.dt)


# Add an ID column that removes the technical replicates information 
mutations.dt[, ID := gsub("^(E1504|E177)_[0-9][0-9]_(1|10|100)_[123]_([12]_...$)", 
                          "\\1_\\2_\\3", 
                          exp, 
                          perl = TRUE)]
# Merge the indel statistics
mutations.stat.dt = merge(mutations.dt, indel.statistics.dt)

# Filter the low viability reads
# This filters out all drugs at a certain concentration were at least 2/3 technical replicates were below 0.45 in at least one biological replicate 
remove_drugs <- mutations.stat.dt %>%
  filter(viab_norm_split < 0.45) %>%
  dplyr::select(conc_char, drug, tech, replicate) %>%
  unique() %>%
  mutate(conc_char_drug = paste(conc_char, drug, sep = " "),
         tech_n = ave(conc_char_drug, conc_char_drug, replicate, FUN = length)) %>%
  filter(tech_n > 1) %>%
  dplyr::select(-tech_n, -tech, -replicate) %>%
  unique()

mutations.stat.dt <- mutations.stat.dt %>%
  mutate(conc_char_drug = paste(conc_char, drug, sep = " ")) %>%
  filter(!conc_char_drug %in% remove_drugs$conc_char_drug) %>%
  dplyr::select(-conc_char_drug, -mut.counts)

### THIS IS COMMENTED OUT BECAUSE WE DONT NEED IT ANYMORE #####
# # Calculate the data now from the summed values. 
# mutations.stat.dt[, c("count", "reads", "norm") := 
#                list(sum(count_split), sum(reads_split), sum(norm_split)), by = c("ID", "barcode", "mutation")]
# mutations.stat.dt[, c("viab_norm", "r_written_pct") := 
#                list(mean(viab_norm_split), mean(r_written_pct_split)), 
#              by = c("ID", "barcode")]
# 
# cols = c("barcode", "ID", "mutation", "norm", "count")
# mutations.pool.dt = mutations.stat.dt[, ..cols]
# mutations.pool.dt = unique(mutations.pool.dt)
# 
# mutations.pool.dt[, norm_pooled := norm/sum(norm), by = ID]
# 
# mutations.pool.dt[, c("freq_pooled", "sum_pooled_bc_reads") := 
#                     list(norm_pooled/sum(norm_pooled, na.rm = TRUE), sum(count)), 
#                   by = c("barcode","ID")]
# 
# mutations.pool.dt[!mutation%in%c(0,NA), 
#                   ratio_indels_pooled := norm_pooled/sum(norm_pooled, na.rm = TRUE), 
#                   by=c("barcode","ID")]
# 
# # Merge the data
# screen.indel.dt = merge(mutations.stat.dt, mutations.pool.dt, 
#                         by = c("barcode", "ID", "mutation", "norm", "count"))

screen.indel.dt = copy(mutations.stat.dt)

# Quick random check of the data for a specific barcode and drug: 
screen.indel.dt[barcode == "ACTGTCGAGTTGTCCG" & drug == "Zebularine" & mutation == -7, 
                -c("mut_type", "file", "seq_barcode", "seq_index", "well", 
                   "barcode", "mutation", "index_length", "drug_no", "drug_well")]

screen.indel.dt[is.na(mutation), ]
```

dim(mutations.dt)
[1] 1956008      33
dim(mutations.pool.dt)
[1] 928364      9
dim(screen.indel.dt)
[1] 1956008      37
## We will also remove samples that not least in 2 technical replicates (out of 3) and are present in at least both biological replicates. 

```{r filter for reproducibility}
screen.indel.dt %>% 
  distinct(concentration, replicate, tech, drug) %>% 
  group_by(concentration, replicate, drug) %>% 
  summarise(count = n()) %>% 
  filter(count < 2)

screen.indel.dt %>% 
  distinct(concentration, replicate, drug) %>% 
  group_by(concentration, drug) %>% 
  summarise(count = n()) %>% 
  filter(count < 2)
```

These two tables are empty, that means that all the samples we have here are all in at least 2 same screen replicates and 2 difference screen replicates.


## Pooling large indels for indel spectrum plotting

```{r}
# c("barcode", "ID", "mutation", "norm", "count", "exp",  "type", "count",  "norm_split", "freq_split", "sum_bc_reads_split", "ratio_indels_split", "reads", "replicate",  "plate", "concentration", "tech", "drug_plate", "well", "seq_barcode", "seq_index", "file", "PCR_type",  "index_length", "drug_no",  "drug_well", "drug", "target",  "r_written_pct", "viability", "viab_norm", "conc_char", "viab_norm_pooled", "norm_pooled", "freq_pooled", "sum_pooled_bc_reads", "ratio_indels_pooled")

# Fix large deletions for every deletion above 25 (we do not sequence deletions larger than 130 bp)
largedels <- as.character(seq(-130, -15))

# "viability", "viab_norm", "viab_norm_pooled", "r_written_pct",
# test.dt = screen.indel.dt[ID == "E1504_100_1_A02" & barcode == "ACTGTCGAGTTGTCCG",]
mutations.large.del.dt = screen.indel.dt[mutation %in% largedels, ]

# Sum large dels
mutations.large.del.sum.dt = 
  mutations.large.del.dt[, lapply(.SD, sum, na.rm=TRUE), 
                         by=c("exp", "barcode"),
                         .SDcols=c("count_split",  
                                   "norm_split", "freq_split", "sum_bc_reads_split",
                                   "ratio_indels_split")]
# Add indel info
mutations.large.del.sum.dt[, c("mutation", "mut_type") := list("<-14", "del")]

mutations.large.del.sum.dt[is.na(mutation), ]

# Make base data table
colslargedels = colnames(mutations.large.del.sum.dt)[3:ncol(mutations.large.del.sum.dt)]
base.dt = screen.indel.dt %>% 
  select(!all_of(colslargedels)) %>% unique()

# Merge the base DT with groupe larde dels
mutations.large.del.sum.base.dt = base.dt %>% 
  left_join(mutations.large.del.dt) %>% 
  unique()

mutations.large.del.sum.base.dt[is.na(mutation), ]


# Fix large insertions for every insertions above 3
largeins <- as.character(seq(3, 20))
mutations.large.ins.dt = screen.indel.dt[mutation %in% largeins, ]
# Sum large ins
mutations.large.ins.sum.dt = mutations.large.ins.dt[, lapply(.SD, sum, na.rm=TRUE),  by=c("exp", "barcode"),
                                                .SDcols=c("count_split",  
                                                          "norm_split", "freq_split", "sum_bc_reads_split",
                                                          "ratio_indels_split")]
# Add indel info
mutations.large.ins.sum.dt[, c("mutation", "mut_type") := list(">2", "ins")]

# Merge the base DT with groupe larde ins
mutations.large.ins.sum.base.dt = base.dt %>% 
  left_join(mutations.large.ins.sum.dt) %>%
  unique()

mutations.large.ins.sum.base.dt[is.na(mutation), ]

large.indels.dt = rbind(mutations.large.del.sum.base.dt, mutations.large.ins.sum.base.dt)

muts <- unique(screen.indel.dt$mutation)
min_indel <- min(as.numeric(muts))
max_indel <- max(as.numeric(muts))
indels <- c("<-14", as.character(seq(min_indel, max_indel)), ">2")

setcolorder(large.indels.dt,colnames(screen.indel.dt))
screen.indel.dt = rbind(screen.indel.dt, large.indels.dt)
screen.indel.dt[, c("sample", "type", "color") :=  list(
  # Add column with controls vs drug for plotting also
  ifelse(drug == "DMSO", "DMSO (neg control)", ifelse(
  drug == "DNA-PKi", "DNA-PKi (NHEJ control)", ifelse(
    drug == "Mirin", "Mirin (MMEJ control)", ifelse(
      drug == "PAO", "PAO (killing control)", "drug")))),
  # Add column to identify core, grouped (large) indels or large indels (individual)
  ifelse(mutation %in% c(largedels, largeins), "large_indel", 
         ifelse(mutation %in% c("<-14", ">2"), "grouped_indel", "core")),
  # Add column with color for plotting ease
  ifelse(mutation == 0, "wt", 
         ifelse(mutation == 1, "NHEJ", 
                ifelse(mutation == -7, "MMEJ", "other"))))]

# Make factor from mutations, so plotting is made easy
screen.indel.dt[, mutation := factor(screen.indel.dt$mutation, levels=indels)]

# Finally remove all the count = 0 now that the ratios have been calculated
```

dim(screen.indel.dt)
[1] 1956008      37
dim(large.indels.dt)
[1] 104566     37
dim(screen.indel.dt)
[1] 2060574      40

## R cleanup
```{r}
rm(list = ls()[grep("^mutations", ls())])
rm(list = ls()[grep("list$", ls())])
rm(list = ls()[grep("large.indels.dt", ls())])
rm(list = ls()[grep("mutations.dt", ls())])
```


## Add identifiers and compute indel ratios

```{r calculate_ratios}
# Calculate NHEJ/MMEJ ratios and efficiences
ratios_tib <- screen.indel.dt %>%
  filter(mutation %in% c("1", "-7")) %>%
  dplyr::distinct(exp, barcode, mutation, ratio_indels_split) %>% 
  pivot_wider(names_from = mutation, 
              values_from = ratio_indels_split, 
              values_fill = 0) %>%
  mutate(freqMMEJ = `-7` / 1,
         freqNHEJ = `1` / 1,
         NHEJMMEJratio = freqMMEJ / freqNHEJ,
         MMEJscore = freqMMEJ / (freqMMEJ + freqNHEJ),
         NHEJscore = freqNHEJ / (freqNHEJ+ freqMMEJ)) %>%
  distinct(exp, barcode, MMEJscore) 


freqs_ratios_tib <- screen.indel.dt %>%
  as_tibble() %>%
  filter(mutation == "0") %>%
  dplyr::distinct(exp, barcode, mutation, freq_split) %>% 
  mutate(freqCut = 1 - freq_split) %>%
  distinct(exp, barcode, freqCut) %>% 
  left_join(ratios_tib) 

screen.indel.dt = merge(screen.indel.dt, freqs_ratios_tib, by = c("exp", "barcode"))
```
dim(screen.indel.dt)
[1] 2060574      40
dim(screen.indel.dt)
[1] 2060574      52

## Calculating the z-scores

### Checking for data normality

```{r calculating z-scores}
# First check if the DMSO data is normally distributed for MMEJscore and freqCut
# Split only (pooled were removed)
for (i in barcodes.clone5) {
  norm_pooled = screen.indel.dt %>%
    filter(drug == "DMSO", barcode == i) %>%
    distinct(ID, barcode, freqCut, MMEJscore, replicate)
  plt1 = qplot(sample = freqCut, data = norm_pooled, color=replicate) +
    theme_bw() +
    ggtitle(paste0("pooled freqCut Barcode: ", i))
  plt2 = qplot(sample = MMEJscore, data = norm_pooled, color=replicate) +
    theme_bw() +
    ggtitle(paste0("pooled MMEJscore Barcode: ", i))
  plot_grid(plt1, plt2)
}
```

## Calculating the z-scores and normalised efficiencies

```{r loading and adding the chromatin data}
# Plate normalization for cutting/repair efficiency - calculate efficiency relative to mean DMSO efficiency per concentration, barcode and replicate
dmso.efficiency <- screen.indel.dt %>%
  filter(drug == "DMSO") %>%
  dplyr::select('DMSO' = freqCut, barcode, replicate, tech) %>%
  mutate(DMSO = ave(DMSO, barcode, replicate, tech, FUN = mean)) %>%
  unique()

screen.indel.dt <- merge(screen.indel.dt, dmso.efficiency, by = c("barcode", "replicate", "tech"))

screen.indel.dt <- screen.indel.dt %>%
  mutate(freqCut_norm_split = freqCut / DMSO) %>%
  dplyr::select(-DMSO)


# Grouped technical replicates
dmso.efficiency <- screen.indel.dt %>%
  filter(drug == "DMSO") %>%
  dplyr::select('DMSO' = freqCut, barcode, replicate) %>%
  mutate(DMSO = ave(DMSO, barcode, replicate, FUN = mean)) %>%
  unique()

screen.indel.dt <- merge(screen.indel.dt, dmso.efficiency, by = c("barcode", "replicate"))

screen.indel.dt <- screen.indel.dt %>%
  mutate(freqCut_mean = ave(freqCut, barcode, replicate, concentration, drug, FUN = mean)) %>%
  mutate(freqCut_norm = freqCut_mean / DMSO) %>%
  dplyr::select(-DMSO, -freqCut_mean)

# Grouped technical & biological replicates
dmso.efficiency <- screen.indel.dt %>%
  filter(drug == "DMSO") %>%
  dplyr::select('DMSO' = freqCut, barcode) %>%
  mutate(DMSO = ave(DMSO, barcode, FUN = mean)) %>%
  unique()

screen.indel.dt <- merge(screen.indel.dt, dmso.efficiency, by = c("barcode"))

screen.indel.dt <- screen.indel.dt %>%
  mutate(freqCut_mean = ave(freqCut, barcode, drug, concentration, FUN = mean)) %>%
  mutate(freqCut_norm_mean = freqCut_mean / DMSO) %>%
  dplyr::select(-DMSO, -freqCut_mean)

# Mean values independent of IPR (mean effect of the drug)
dmso.efficiency <- screen.indel.dt %>%
  filter(drug == "DMSO") %>%
  dplyr::select('DMSO' = freqCut, replicate) %>%
  mutate(DMSO = ave(DMSO, replicate, FUN = mean)) %>%
  unique()

screen.indel.dt <- merge(screen.indel.dt, dmso.efficiency, by = c("replicate"))

screen.indel.dt <- screen.indel.dt %>%
  mutate(freqCut_drug = ave(freqCut, replicate, drug, concentration, FUN = mean)) %>%
  mutate(freqCut_norm_drug = freqCut_drug / DMSO) %>%
  dplyr::select(-DMSO, -freqCut_drug)

# Mean values independent of IPR (mean effect of the drug) & mean over replicates
dmso.efficiency <- screen.indel.dt %>%
  filter(drug == "DMSO") %>%
  dplyr::select('DMSO' = freqCut) %>%
  mutate(DMSO = ave(DMSO, FUN = mean)) %>%
  unique()

screen.indel.dt <- screen.indel.dt %>%
  mutate(freqCut_mean_drug = ave(freqCut, drug, concentration, FUN = mean)) %>%
  mutate(freqCut_norm_mean_drug = freqCut_mean_drug / dmso.efficiency$DMSO) %>%
  dplyr::select(-freqCut_mean_drug)


# MMEJscore z-score - calculate drug scores relative to DMSO MMEJ score distribution per concentration, barcode and replicate
dmso.mmej.score <- screen.indel.dt %>%
  filter(drug == "DMSO") %>%
  dplyr::select('DMSO' = MMEJscore, barcode, replicate) %>%
  mutate(mean_DMSO = ave(DMSO, barcode, replicate, FUN = mean), 
         sd_DMSO = ave(DMSO, barcode, replicate, FUN = sd)) %>%
  dplyr::select(-DMSO) %>%
  unique()

screen.indel.dt <- merge(screen.indel.dt, dmso.mmej.score)

screen.indel.dt <- screen.indel.dt %>%
  mutate(MMEJ_score_mean = ave(MMEJscore, drug, concentration, barcode, replicate, FUN = mean)) %>%
  mutate(MMEJ_zscore = (MMEJ_score_mean - mean_DMSO)/ sd_DMSO) %>%
  dplyr::select(-mean_DMSO, -sd_DMSO)


# Mean values independent of IPR (mean effect of the drug)
dmso.mmej.score <- screen.indel.dt %>%
  filter(drug == "DMSO") %>%
  dplyr::select('DMSO' = MMEJscore, replicate) %>%
  mutate(mean_DMSO = ave(DMSO, replicate, FUN = mean), 
         sd_DMSO = ave(DMSO, replicate, FUN = sd)) %>%
  dplyr::select(-DMSO) %>%
  unique()

screen.indel.dt <- merge(screen.indel.dt, dmso.mmej.score)

screen.indel.dt <- screen.indel.dt %>%
  mutate(MMEJ_score_mean_drug = ave(MMEJscore, drug, concentration, replicate, FUN = mean)) %>%
  mutate(MMEJ_zscore_drug = (MMEJ_score_mean_drug - mean_DMSO)/ sd_DMSO) %>%
  dplyr::select(-mean_DMSO, -sd_DMSO)

#screen.indel.dt = screen.indel.dt[count != 0]
```

dim(screen.indel.dt)
[1] 2060574      52
dim(screen.indel.dt)
[1] 2060574      72

# Data export

## Prepare data for export

```{r split data sepereately}
#### I took a shortcut here to just extract the relevant data for script 4 - this can be changed if needed
# Select relevant columns from data table
screen.indel.dt.export <- screen.indel.dt %>%
  distinct(replicate, barcode, tech, exp, ID, plate, concentration, drug_plate, well, drug, target, conc_char, sample, freqCut, MMEJscore, freqCut_norm_split, freqCut_norm,
           freqCut_norm_mean, freqCut_norm_drug, freqCut_norm_mean_drug, MMEJ_score_mean, MMEJ_score_mean_drug, MMEJ_zscore, MMEJ_zscore_drug, 'viability' = viab_norm_split)
  
# Combine z-scores of the two biological replicates: stouffer's method = sum(z-scores)/sqrt(number_of_z-scores)
zscores_comb <- screen.indel.dt.export %>%
  distinct(MMEJ_zscore, drug, conc_char, barcode) %>%
  mutate(MMEJ_zscore_comb = ave(MMEJ_zscore, drug, conc_char, barcode, FUN = function(x) sum(x)/sqrt(length(x)))) 

zscores_comb_drug <- screen.indel.dt.export %>%
  distinct(MMEJ_zscore_drug, drug, conc_char) %>%
  mutate(MMEJ_zscore_drug_comb = ave(MMEJ_zscore_drug, drug, conc_char, FUN = function(x) sum(x)/sqrt(length(x)))) %>%
  distinct(MMEJ_zscore_drug_comb, drug, conc_char)

screen.indel.dt.export <- merge(screen.indel.dt.export, zscores_comb)
screen.indel.dt.export <- merge(screen.indel.dt.export, zscores_comb_drug, by = c("conc_char", "drug"))

```


```{r split data sepereately}
#### not executed from here on atm
# Make base table without any numeric data.
num.base.dt = screen.indel.dt %>% select(barcode, exp, plate, concentration, drug_plate, drug_no) %>% unique()

base.dt = screen.indel.dt %>% 
  select_if(negate(is.numeric)) %>% #### FIX THIS
  dplyr::select(-mutation, -mut_type, -type, -color) %>% 
  unique() %>% 
  left_join(num.base.dt)


# Make tibble with only the split technical replicates data.
screen.indel.dt$tech <- as.character(screen.indel.dt$tech)
base.mut.dt = screen.indel.dt %>% 
  select_if(negate(is.numeric)) %>% 
  unique() %>%
  left_join(num.base.dt)


split.dt = screen.indel.dt %>% 
  dplyr::select(barcode, exp, mutation, contains("split"))

screen_indel_split_tib = base.mut.dt %>%
  left_join(split.dt, 
            by = c("barcode", "exp", "mutation")) %>% 
  unique() %>%
  as_tibble()

# Make tibble with only the pooled technical replicates data. 
screen_indel_mut_tib = screen.indel.dt %>%
  dplyr::select(!contains("split"), 
                -plate, -exp, -seq_barcode, 
                -seq_index, -file) %>%
  unique() %>%
  as_tibble()

# Table with only ratios from the pooled set
screen_indel_tib = screen.indel.dt %>%
  dplyr::select(!contains("split"), 
                -plate, -exp, -seq_barcode, 
                -seq_index, -file, -mutation, 
                -mut_type, -type, -color, 
                -tech, -norm, -count) %>%
  unique() %>%
  as_tibble()
```

```{r}
# For MMEJ z-score
mmejzscore_matrix = screen_indel_split_tib %>%  
  filter(sample == "drug") %>%
  mutate(ID = paste(gsub("^E.*_(.*_[12]_...)$", "\\1\\2", ID), barcode, sep = "_")) %>% 
  distinct(ID, MMEJ_zscore_split, replicate, tech) %>%
  pivot_wider(., names_from = c("replicate", "tech"), values_from = "MMEJ_zscore_split") %>%
  column_to_rownames(., var = "ID")
# 
chart.Correlation(mmejzscore_matrix, histogram=TRUE, pch=19)

# For standard MMEJ score
mmejscore_matrix = screen_indel_split_tib %>%  
  filter(sample == "drug") %>%
  mutate(ID = paste(gsub("^E.*_(.*_[12]_...)$", "\\1\\2", ID), barcode, sep = "_")) %>% 
  distinct(ID, MMEJscore_split, replicate, tech) %>%
  pivot_wider(., names_from = c("replicate", "tech"), values_from = "MMEJscore_split") %>%
  column_to_rownames(., var = "ID")
# 
chart.Correlation(mmejscore_matrix, histogram=TRUE, pch=19)

MMEJscorevar = mmejscore_matrix %>%
  rownames_to_column(var = "ID") %>%
  pivot_longer(.,cols = starts_with("E"), names_to = "rep") %>%
  group_by(rep)

MMEJscorevar %>%
  summarise(
    count = n(),
    mean = mean(value, na.rm = TRUE),
    sd = sd(value, na.rm = TRUE))
  

# Compute the analysis of variance
res.aov <- aov(value ~ rep, data = MMEJscorevar)
# Summary of the analysis
summary(res.aov)

# Compute the analysis of variance
res.aov <- aov(value ~ rep, data = filter(MMEJscorevar, grepl("E177", rep)))
# Summary of the analysis
summary(res.aov)

# Compute the analysis of variance
res.aov <- aov(value ~ rep, data = filter(MMEJscorevar, grepl("E1504", rep)))
# Summary of the analysis
summary(res.aov)

fligner.test(value ~ rep, data = MMEJscorevar)
fligner.test(value ~ rep, data = filter(MMEJscorevar, grepl("E177", rep)))
fligner.test(value ~ rep, data = filter(MMEJscorevar, !grepl("E177", rep))) 

```

```{r distribution of the MMEJ score in the controls}
mmejscore_DMSO_matrix_list = screen_indel_split_tib %>%  
  filter(drug == "DMSO") %>%
  mutate(ID = gsub("^E.*_.*_([12]_...)$", "\\1\\2", ID)) %>% 
  distinct(ID, MMEJscore_split, replicate, tech, concentration, barcode) %>%
  pivot_wider(names_from = c("replicate", "tech", "concentration"), 
              values_from = "MMEJscore_split") %>%
  group_split(barcode, .keep = FALSE)

mmejscore_DMSO_matrix_list_new = lapply(mmejscore_DMSO_matrix_list, '[', -1)

# MMEJscoreDMSOvar = mmejscore_DMSO_matrix %>%
#   rownames_to_column(var = "ID") %>%
#   pivot_longer(cols = starts_with("E"), names_to = "rep") %>%
#   group_by(rep)

sep_conc = screen_indel_split_tib %>%  
  filter(drug == "DMSO") %>%
  mutate(ID = gsub("^E.*_(.*_.*)_[12]_...$", "\\1", exp),
         plates = paste(replicate, tech, concentration, sep = "_")) %>% 
  distinct(ID,plates, freqCut_split, MMEJscore_split, replicate, tech, concentration, barcode)

for (i in unique(sep_conc$barcode)) {
  btest = bartlett.test(MMEJscore_split ~ plates, data = filter(sep_conc, barcode == i))
  print(btest)
}

sep_conc %>% 
  filter(barcode == "ACCCCTAAAGGCGCTG") %>% 
  ggplot(., aes(plates, MMEJscore_split)) + geom_jitter()

sep_conc %>% 
  filter(barcode == "ACCCCTAAAGGCGCTG") %>% 
  ggplot(., aes(plates, freqCut_split)) + geom_jitter()

sep_conc %>%  
  ggplot(., aes(plates, freqCut_split, color = barcode)) + geom_jitter()

sep_conc %>%  
  ggplot(., aes(plates, MMEJscore_split, color = barcode)) + geom_jitter()

comb_conc = screen_indel_split_tib %>%  
  filter(drug == "DMSO") %>%
  mutate(ID = gsub("^E.*_(.*_.*)_[12]_...$", "\\1", exp),
         plates = paste(replicate, tech, sep = "_")) %>% 
  distinct(ID,plates, freqCut_split, MMEJscore_split, replicate, tech, barcode)

for (i in unique(comb_conc$barcode)) {
  btest = bartlett.test(MMEJscore_split ~ plates, data = filter(comb_conc, barcode == i))
  print(btest)
  }
  
comb_conc %>% 
  filter(barcode == "ACCCCTAAAGGCGCTG") %>% 
  ggplot(., aes(plates, MMEJscore_split)) + geom_jitter()

comb_conc %>%  
  ggplot(., aes(plates, freqCut_split, color = barcode)) + geom_jitter()

comb_conc %>%  
  ggplot(., aes(plates, MMEJscore_split, color = barcode)) + geom_jitter()

mmejscore_DMSO_tib = screen_indel_split_tib %>%  
  filter(drug == "DMSO") %>%
  mutate(ID = gsub("^E.*_(.*_.*)_[12]_...$", "\\1", exp)) %>%
  distinct(ID, MMEJscore_split, replicate, tech, concentration, drug, barcode)

mmejscore_DMSO_tib %>% 
  ggplot(., aes(ID, MMEJscore_split)) + 
  geom_jitter() + 
  facet_grid(barcode ~ replicate, scales = "free_y")
```



## Loading and binding the chromatin data
We'll use the table from Schep et al. 2021 to bind directly all the relevant chromatin data. 
```{r chromatin data}
clone5_chrom_tib <- readRDS("/DATA/projects/DSBrepair/data/R/rs20200519_clone5_newdoms_chromatin.RDS")

screen.indel.dt.export <- screen.indel.dt.export %>% left_join(clone5_chrom_tib, by = "barcode")


screen_indel_mut_tib %<>% left_join(clone5_chrom_tib, by = "barcode")
```
## Processed data export The files will be saved in the processed data folder.
```{r export}
# The mutations list that can be loaded for the indel spectra plots.
filename <- SetFileName("_episcreen_mutations.RDS", "rs")
saveRDS(screen_indel_mut_tib, file = filename)

# The ratios list of the split technical replicates
filename <- SetFileName("_episcreen_ratios_split.RDS", "rs")
saveRDS(screen_indel_split_tib, file = filename)

# The ratios list of the merged technical replicates
filename <- SetFileName("_episcreen_ratios.RDS", "rs")
saveRDS(screen_indel_tib, file = filename)
```

# Conclusions 
Looks all fine! Now, we can generate indel plots and look in detail at the ratios.

# Bibliography
```{r citations}
cite_packages()
```

# Session Info
```{r session_info}
sessionInfo()
getwd()
date()
paste("Run time: ",format(Sys.time()-StartTime))
rm(list = ls(all.names = TRUE)) #will clear all objects includes hidden objects.
gc() #free up memrory and report the memory usage.
```

